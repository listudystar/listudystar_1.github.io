
# RF-天气最高温度预测

## （连续值------回归问题）

### 【备注】标签值用SERIES类型，该类型没有column

### >> 完成三项任务：

1. 使用RF完成基本建模
   * A.处理数据
   * B.观察特征
   * C.完成建模
   * D.可视化展示分析

2. 观察数据量与特征个数对结果的影响（在算法一致的前提下）
   * A.加大数据个数
   * B.观察结果变化
   * C.重新考虑特征工程
   * D.引入新特征观察结果走势

3. 对RF进行调参，找到最合适参数
   * 机器学习中两种经典调参方法


```python
# 三大件
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
```

## 1. 使用RF完成基本建模

### >> 1. 加载数据（观察数据，去除NAN值，输出数据特征）


```python
data = pd.read_csv('data/temps.csv')
data.head(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>week</th>
      <th>temp_2</th>
      <th>temp_1</th>
      <th>average</th>
      <th>actual</th>
      <th>friend</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2016</td>
      <td>1</td>
      <td>1</td>
      <td>Fri</td>
      <td>45</td>
      <td>45</td>
      <td>45.6</td>
      <td>45</td>
      <td>29</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2016</td>
      <td>1</td>
      <td>2</td>
      <td>Sat</td>
      <td>44</td>
      <td>45</td>
      <td>45.7</td>
      <td>44</td>
      <td>61</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2016</td>
      <td>1</td>
      <td>3</td>
      <td>Sun</td>
      <td>45</td>
      <td>44</td>
      <td>45.8</td>
      <td>41</td>
      <td>56</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2016</td>
      <td>1</td>
      <td>4</td>
      <td>Mon</td>
      <td>44</td>
      <td>41</td>
      <td>45.9</td>
      <td>40</td>
      <td>53</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2016</td>
      <td>1</td>
      <td>5</td>
      <td>Tues</td>
      <td>41</td>
      <td>40</td>
      <td>46.0</td>
      <td>44</td>
      <td>41</td>
    </tr>
  </tbody>
</table>
</div>




```python
data.shape
```




    (348, 9)




```python
data = data.dropna() #去除NAN值
data.shape
```




    (348, 9)




```python
data.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>temp_2</th>
      <th>temp_1</th>
      <th>average</th>
      <th>actual</th>
      <th>friend</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>348.0</td>
      <td>348.000000</td>
      <td>348.000000</td>
      <td>348.000000</td>
      <td>348.000000</td>
      <td>348.000000</td>
      <td>348.000000</td>
      <td>348.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2016.0</td>
      <td>6.477011</td>
      <td>15.514368</td>
      <td>62.511494</td>
      <td>62.560345</td>
      <td>59.760632</td>
      <td>62.543103</td>
      <td>60.034483</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.0</td>
      <td>3.498380</td>
      <td>8.772982</td>
      <td>11.813019</td>
      <td>11.767406</td>
      <td>10.527306</td>
      <td>11.794146</td>
      <td>15.626179</td>
    </tr>
    <tr>
      <th>min</th>
      <td>2016.0</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>35.000000</td>
      <td>35.000000</td>
      <td>45.100000</td>
      <td>35.000000</td>
      <td>28.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>2016.0</td>
      <td>3.000000</td>
      <td>8.000000</td>
      <td>54.000000</td>
      <td>54.000000</td>
      <td>49.975000</td>
      <td>54.000000</td>
      <td>47.750000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>2016.0</td>
      <td>6.000000</td>
      <td>15.000000</td>
      <td>62.500000</td>
      <td>62.500000</td>
      <td>58.200000</td>
      <td>62.500000</td>
      <td>60.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2016.0</td>
      <td>10.000000</td>
      <td>23.000000</td>
      <td>71.000000</td>
      <td>71.000000</td>
      <td>69.025000</td>
      <td>71.000000</td>
      <td>71.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2016.0</td>
      <td>12.000000</td>
      <td>31.000000</td>
      <td>92.000000</td>
      <td>92.000000</td>
      <td>77.400000</td>
      <td>92.000000</td>
      <td>95.000000</td>
    </tr>
  </tbody>
</table>
</div>



##### 结论：无NAN值；week为属性值，需要进行转换；特征为month,day,week,temp_2,temp_1,average,frined，标签为actual

### >> 2. 处理数据（a. 将时间数据重新构造为时间戳，用于方便显示；b. 将属性数据或类别数据进行ONE-HOT编码）

#### a. 将时间数据重新构造为时间戳，用于方便显示


```python
import datetime

years = data['year']
months = data['month']
days = data['day']

# 构造固定格式的时间戳
dates = [str(int(year)) + '-' + str(int(month)) + '-' + str(int(day)) for year, month, day in zip(years, months, days)]
dates = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in dates]
```


```python
dates[:5]
```




    [datetime.datetime(2016, 1, 1, 0, 0),
     datetime.datetime(2016, 1, 2, 0, 0),
     datetime.datetime(2016, 1, 3, 0, 0),
     datetime.datetime(2016, 1, 4, 0, 0),
     datetime.datetime(2016, 1, 5, 0, 0)]



#### b. 将属性数据或类别数据进行ONE-HOT编码（data 数据中week为类别数据，需要用独热编码处理）


```python
# Pands自动判断特征，用one-hot encoding处理
data = pd.get_dummies(data)
data.head(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>temp_2</th>
      <th>temp_1</th>
      <th>average</th>
      <th>actual</th>
      <th>friend</th>
      <th>week_Fri</th>
      <th>week_Mon</th>
      <th>week_Sat</th>
      <th>week_Sun</th>
      <th>week_Thurs</th>
      <th>week_Tues</th>
      <th>week_Wed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2016</td>
      <td>1</td>
      <td>1</td>
      <td>45</td>
      <td>45</td>
      <td>45.6</td>
      <td>45</td>
      <td>29</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2016</td>
      <td>1</td>
      <td>2</td>
      <td>44</td>
      <td>45</td>
      <td>45.7</td>
      <td>44</td>
      <td>61</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2016</td>
      <td>1</td>
      <td>3</td>
      <td>45</td>
      <td>44</td>
      <td>45.8</td>
      <td>41</td>
      <td>56</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2016</td>
      <td>1</td>
      <td>4</td>
      <td>44</td>
      <td>41</td>
      <td>45.9</td>
      <td>40</td>
      <td>53</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2016</td>
      <td>1</td>
      <td>5</td>
      <td>41</td>
      <td>40</td>
      <td>46.0</td>
      <td>44</td>
      <td>41</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



### >> 3. 数据展示（查看趋势）


```python
plt.style.use('fivethirtyeight')
# 设置布局
fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize = (10,10))
fig.autofmt_xdate(rotation = 45)

# 标签趋势
ax1.plot(dates, data['actual'])
ax1.set_xlabel('Date'); ax1.set_ylabel('Temperature'); ax1.set_title('acutal')

# 前一天温度
ax2.plot(dates, data['temp_1'])
ax2.set_xlabel('Date'); ax2.set_ylabel('Temperature'); ax2.set_title('temp_1')

# 前两天温度
ax3.plot(dates, data['temp_2'])
ax3.set_xlabel('Date'); ax3.set_ylabel('Temperature'); ax3.set_title('temp_2')

# Friend Estimate
ax4.plot(dates, data['friend'])
ax4.set_xlabel('Date'); ax4.set_ylabel('Temperature'); ax4.set_title('average')

plt.tight_layout(pad=2)
```


![image](https://github.com/listudystar/listudystar.github.io/raw/master/_posts/20190728_1.png)


##### 结论：数据趋势基本相似，与温度的关系较一致

### >> 4. 数据切分（训练集和测试集）


```python
data = data.drop(['year'],axis = 1) #删除无用列(因为只有2016年数据，故删除)
```


```python
data = data.sample(frac = 1, random_state = 0) #洗牌
```


```python
X_data = data.iloc[:, data.columns != 'actual'] # 数据集特征值
y_data = data.iloc[:, data.columns == 'actual']['actual'] # 数据集标签值

```


```python
X_data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>month</th>
      <th>day</th>
      <th>temp_2</th>
      <th>temp_1</th>
      <th>average</th>
      <th>friend</th>
      <th>week_Fri</th>
      <th>week_Mon</th>
      <th>week_Sat</th>
      <th>week_Sun</th>
      <th>week_Thurs</th>
      <th>week_Tues</th>
      <th>week_Wed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
      <td>1</td>
      <td>7</td>
      <td>44</td>
      <td>51</td>
      <td>46.2</td>
      <td>38</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>52</th>
      <td>2</td>
      <td>24</td>
      <td>51</td>
      <td>60</td>
      <td>50.8</td>
      <td>46</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>269</th>
      <td>10</td>
      <td>13</td>
      <td>62</td>
      <td>66</td>
      <td>60.6</td>
      <td>57</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>45</th>
      <td>2</td>
      <td>17</td>
      <td>55</td>
      <td>56</td>
      <td>50.0</td>
      <td>46</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>294</th>
      <td>11</td>
      <td>8</td>
      <td>61</td>
      <td>63</td>
      <td>52.7</td>
      <td>49</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
y_data.head()
```




    6      45
    52     59
    269    60
    45     57
    294    71
    Name: actual, dtype: int64




```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.25,random_state = 0)
```


```python
print('训练特征shape:', X_train.shape)
print('训练标签shape:', y_train.shape)
print('测试特征shape:', X_test.shape)
print('测试标签shape:', y_test.shape)
```

    训练特征shape: (261, 13)
    训练标签shape: (261,)
    测试特征shape: (87, 13)
    测试标签shape: (87,)
    

### >> 4. 构建模型（RF模型）


```python
from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(n_estimators= 1000, random_state=0) # RF模型对象

rf.fit(X_train,y_train) # 训练
```




    RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
                          max_features='auto', max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=1000,
                          n_jobs=None, oob_score=False, random_state=0, verbose=0,
                          warm_start=False)



### >> 5. 测试模型（RF模型）


```python
y_pred = rf.predict(X_test)
```

##### MAE指标（LOSS值）


```python
errors = abs(y_pred  - np.array(y_test))

# MAE
print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')
```

    Mean Absolute Error: 3.76 degrees.
    

##### MAPE指标（LOSS值）：当数据样本量非常小时，先用MAPE指标评估（平均绝对百分误差）


```python
mape = 100 * (errors / np.array(y_test))

# 计算准确率
accuracy = 100 - np.mean(mape)
print('Accuracy:', round(accuracy, 2), '%.')
```

    Accuracy: 94.15 %.
    

### >> 5 RF可视化（重新利用预剪枝参数训练RF,并进行显示）


```python
rf_small = RandomForestRegressor(n_estimators=10, max_depth = 3, random_state = 0) # 预剪枝（构造1000棵树，深度5层）
rf_small.fit(X_train, y_train)
```




    RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,
                          max_features='auto', max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_impurity_split=None,
                          min_samples_leaf=1, min_samples_split=2,
                          min_weight_fraction_leaf=0.0, n_estimators=10,
                          n_jobs=None, oob_score=False, random_state=0, verbose=0,
                          warm_start=False)




```python
X_train.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>month</th>
      <th>day</th>
      <th>temp_2</th>
      <th>temp_1</th>
      <th>average</th>
      <th>friend</th>
      <th>week_Fri</th>
      <th>week_Mon</th>
      <th>week_Sat</th>
      <th>week_Sun</th>
      <th>week_Thurs</th>
      <th>week_Tues</th>
      <th>week_Wed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>299</th>
      <td>11</td>
      <td>13</td>
      <td>63</td>
      <td>59</td>
      <td>51.4</td>
      <td>64</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>158</th>
      <td>6</td>
      <td>10</td>
      <td>67</td>
      <td>65</td>
      <td>68.8</td>
      <td>73</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>176</th>
      <td>6</td>
      <td>28</td>
      <td>78</td>
      <td>85</td>
      <td>72.4</td>
      <td>67</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>224</th>
      <td>8</td>
      <td>15</td>
      <td>90</td>
      <td>83</td>
      <td>76.6</td>
      <td>70</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>322</th>
      <td>12</td>
      <td>6</td>
      <td>46</td>
      <td>40</td>
      <td>46.4</td>
      <td>56</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



##### a. 安装 graphviz ; b. 安装pydot


```python
#要可视化显示 首先需要安装 graphviz   http://www.graphviz.org/Download..php
from sklearn.tree import export_graphviz
import pydot #pip install pydot
```


```python
#要可视化显示 首先需要安装 graphviz   http://www.graphviz.org/Download..php
import os
os.environ["PATH"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/' # 安装好graphviz 软件后，需要将环境变量更新

dot_data = \
    export_graphviz(
        rf_small.estimators_[9], # 【改】随机森林的第几棵树
        out_file = None,
        feature_names = list(data.columns.drop(['actual'])), # 【改】特征名改
        rounded = True, 
        precision = 1
    )
```


```python
import pydotplus
graph = pydotplus.graph_from_dot_data(dot_data)  # 【改】特征名改
graph.get_nodes()[7].set_fillcolor("#FFF2DD")
from IPython.display import Image
Image(graph.create_png())
```




![image](https://github.com/listudystar/listudystar.github.io/raw/master/_posts/20190728_2.png)



##### 解释：每个节点中的 第一行表示切分特征及切分点，第二行表示RF回归问题的loss_value，第三行表示节点个数，第四行表示所有值点的平均值

### >> 6 特征重要性


```python
importances = pd.Series(rf_small.feature_importances_, index = list(data.columns.drop(['actual']))).sort_values(ascending = False)
importances
```




    temp_1        0.631529
    average       0.361926
    friend        0.002523
    temp_2        0.001760
    month         0.001268
    day           0.000993
    week_Wed      0.000000
    week_Tues     0.000000
    week_Thurs    0.000000
    week_Sun      0.000000
    week_Sat      0.000000
    week_Mon      0.000000
    week_Fri      0.000000
    dtype: float64




```python
# 作图
x_values = list(range(len(importances))) # x_list
plt.bar(x_values, importances, orientation = 'vertical') # bar图
plt.xticks(x_values, importances.index, rotation='vertical') # 设置x显示值
plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances') # 轴显示值
```




    Text(0.5, 1.0, 'Variable Importances')




![image](https://github.com/listudystar/listudystar.github.io/raw/master/_posts/20190728_3.png)


### >> 6 用最重要的特征进行训练


```python
X_data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>month</th>
      <th>day</th>
      <th>temp_2</th>
      <th>temp_1</th>
      <th>average</th>
      <th>friend</th>
      <th>week_Fri</th>
      <th>week_Mon</th>
      <th>week_Sat</th>
      <th>week_Sun</th>
      <th>week_Thurs</th>
      <th>week_Tues</th>
      <th>week_Wed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
      <td>1</td>
      <td>7</td>
      <td>44</td>
      <td>51</td>
      <td>46.2</td>
      <td>38</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>52</th>
      <td>2</td>
      <td>24</td>
      <td>51</td>
      <td>60</td>
      <td>50.8</td>
      <td>46</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>269</th>
      <td>10</td>
      <td>13</td>
      <td>62</td>
      <td>66</td>
      <td>60.6</td>
      <td>57</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>45</th>
      <td>2</td>
      <td>17</td>
      <td>55</td>
      <td>56</td>
      <td>50.0</td>
      <td>46</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>294</th>
      <td>11</td>
      <td>8</td>
      <td>61</td>
      <td>63</td>
      <td>52.7</td>
      <td>49</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
rf_most_important = RandomForestRegressor(n_estimators= 1000, random_state=42) # 创建RF对象

train_important = X_train[['temp_1','average']]
test_important = X_test[['temp_1','average']]

rf_most_important.fit(train_important, y_train) # 训练

predictions = rf_most_important.predict(test_important) # 预测

errors = abs(predictions - np.array(y_test))

# Display the performance metrics
print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')

mape = np.mean(100 * (errors / np.array(y_test)))
accuracy = 100 - mape

print('Accuracy:', round(accuracy, 2), '%.')
```

    Mean Absolute Error: 3.94 degrees.
    Accuracy: 93.78 %.
    

### >> 7 图示预测值与真实值之间的差异


```python
dates

# Plot the actual values
plt.plot(range(len(y_test.index)), y_test, 'b-', label = 'actual')

# Plot the predicted values
plt.plot(range(len(y_test.index)), predictions, 'ro', label = 'prediction')
plt.xticks(rotation = '60'); 
plt.legend()

# Graph labels
plt.xlabel('Date'); plt.ylabel('Maximum Temperature (F)'); plt.title('Actual and Predicted Values');

```


![image](https://github.com/listudystar/listudystar.github.io/raw/master/_posts/20190728_4.png)


##### 分析：做出该图，查看大方向无问题，再扣细节（看起来还可以，这个走势看出模型已经基本掌握，接下来深入数据中）

##  考虑几个问题：
### 1） 如果可用的数据量增大，会对结果有什么影响？
### 2） 加入新特征会改进模型吗？时间效率如何？

## 2. 观察数据量与特征个数对结果的影响（在算法一致的前提下）

### >> 1. 加载数据（观察数据，去除NAN值，，去除无用列，输出数据特征）


```python
features = pd.read_csv('data/temps_extended.csv')
features.head(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>weekday</th>
      <th>ws_1</th>
      <th>prcp_1</th>
      <th>snwd_1</th>
      <th>temp_2</th>
      <th>temp_1</th>
      <th>average</th>
      <th>actual</th>
      <th>friend</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>Sat</td>
      <td>4.92</td>
      <td>0.00</td>
      <td>0</td>
      <td>36</td>
      <td>37</td>
      <td>45.6</td>
      <td>40</td>
      <td>40</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011</td>
      <td>1</td>
      <td>2</td>
      <td>Sun</td>
      <td>5.37</td>
      <td>0.00</td>
      <td>0</td>
      <td>37</td>
      <td>40</td>
      <td>45.7</td>
      <td>39</td>
      <td>50</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011</td>
      <td>1</td>
      <td>3</td>
      <td>Mon</td>
      <td>6.26</td>
      <td>0.00</td>
      <td>0</td>
      <td>40</td>
      <td>39</td>
      <td>45.8</td>
      <td>42</td>
      <td>42</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011</td>
      <td>1</td>
      <td>4</td>
      <td>Tues</td>
      <td>5.59</td>
      <td>0.00</td>
      <td>0</td>
      <td>39</td>
      <td>42</td>
      <td>45.9</td>
      <td>38</td>
      <td>59</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011</td>
      <td>1</td>
      <td>5</td>
      <td>Wed</td>
      <td>3.80</td>
      <td>0.03</td>
      <td>0</td>
      <td>42</td>
      <td>38</td>
      <td>46.0</td>
      <td>45</td>
      <td>39</td>
    </tr>
  </tbody>
</table>
</div>



* ws_1：前一天的风速
* prcp_1: 前一天的降水
* snwd_1：前一天的积雪深度


```python
features.shape
```




    (2191, 12)



##### 新数据规模（2191，12），新数据规模发生变化，数据量扩充为2191条，并加入了新天气指标


```python
features = features.dropna() #去除NAN值
features.shape
```




    (2191, 12)




```python
features.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>ws_1</th>
      <th>prcp_1</th>
      <th>snwd_1</th>
      <th>temp_2</th>
      <th>temp_1</th>
      <th>average</th>
      <th>actual</th>
      <th>friend</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>2191.000000</td>
      <td>2191.000000</td>
      <td>2191.000000</td>
      <td>2191.000000</td>
      <td>2191.000000</td>
      <td>2191.000000</td>
      <td>2191.000000</td>
      <td>2191.000000</td>
      <td>2191.000000</td>
      <td>2191.000000</td>
      <td>2191.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2013.501597</td>
      <td>6.523505</td>
      <td>15.713829</td>
      <td>7.371734</td>
      <td>0.116276</td>
      <td>0.010041</td>
      <td>61.173893</td>
      <td>61.177545</td>
      <td>60.285897</td>
      <td>61.177545</td>
      <td>60.313555</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.709461</td>
      <td>3.449872</td>
      <td>8.801867</td>
      <td>3.154971</td>
      <td>0.251575</td>
      <td>0.153764</td>
      <td>13.085681</td>
      <td>13.082281</td>
      <td>10.732582</td>
      <td>13.081339</td>
      <td>15.871568</td>
    </tr>
    <tr>
      <th>min</th>
      <td>2011.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.890000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>29.000000</td>
      <td>29.000000</td>
      <td>45.100000</td>
      <td>29.000000</td>
      <td>25.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>2012.000000</td>
      <td>4.000000</td>
      <td>8.000000</td>
      <td>5.140000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>51.000000</td>
      <td>51.000000</td>
      <td>50.100000</td>
      <td>51.000000</td>
      <td>49.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>2014.000000</td>
      <td>7.000000</td>
      <td>16.000000</td>
      <td>6.710000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>60.000000</td>
      <td>60.000000</td>
      <td>58.800000</td>
      <td>60.000000</td>
      <td>60.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2015.000000</td>
      <td>10.000000</td>
      <td>23.000000</td>
      <td>9.170000</td>
      <td>0.120000</td>
      <td>0.000000</td>
      <td>71.000000</td>
      <td>71.000000</td>
      <td>70.200000</td>
      <td>71.000000</td>
      <td>71.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2017.000000</td>
      <td>12.000000</td>
      <td>31.000000</td>
      <td>21.250000</td>
      <td>2.200000</td>
      <td>3.000000</td>
      <td>96.000000</td>
      <td>96.000000</td>
      <td>77.400000</td>
      <td>96.000000</td>
      <td>97.000000</td>
    </tr>
  </tbody>
</table>
</div>



### >> 2. 处理数据（a. 将时间数据重新构造为时间戳，用于方便显示；b. 将属性数据或类别数据进行ONE-HOT编码）

#### a. 将时间数据重新构造为时间戳，用于方便显示


```python
import datetime

years = features['year']
months = features['month']
days = features['day']

# 构造固定格式的时间戳
dates = [str(int(year)) + '-' + str(int(month)) + '-' + str(int(day)) for year, month, day in zip(years, months, days)]
dates = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in dates]
```


```python
dates[:5]
```




    [datetime.datetime(2011, 1, 1, 0, 0),
     datetime.datetime(2011, 1, 2, 0, 0),
     datetime.datetime(2011, 1, 3, 0, 0),
     datetime.datetime(2011, 1, 4, 0, 0),
     datetime.datetime(2011, 1, 5, 0, 0)]




```python
# Pands自动判断特征，用one-hot encoding处理
features = pd.get_dummies(features)
features.head(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>ws_1</th>
      <th>prcp_1</th>
      <th>snwd_1</th>
      <th>temp_2</th>
      <th>temp_1</th>
      <th>average</th>
      <th>actual</th>
      <th>friend</th>
      <th>weekday_Fri</th>
      <th>weekday_Mon</th>
      <th>weekday_Sat</th>
      <th>weekday_Sun</th>
      <th>weekday_Thurs</th>
      <th>weekday_Tues</th>
      <th>weekday_Wed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>4.92</td>
      <td>0.00</td>
      <td>0</td>
      <td>36</td>
      <td>37</td>
      <td>45.6</td>
      <td>40</td>
      <td>40</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011</td>
      <td>1</td>
      <td>2</td>
      <td>5.37</td>
      <td>0.00</td>
      <td>0</td>
      <td>37</td>
      <td>40</td>
      <td>45.7</td>
      <td>39</td>
      <td>50</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011</td>
      <td>1</td>
      <td>3</td>
      <td>6.26</td>
      <td>0.00</td>
      <td>0</td>
      <td>40</td>
      <td>39</td>
      <td>45.8</td>
      <td>42</td>
      <td>42</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011</td>
      <td>1</td>
      <td>4</td>
      <td>5.59</td>
      <td>0.00</td>
      <td>0</td>
      <td>39</td>
      <td>42</td>
      <td>45.9</td>
      <td>38</td>
      <td>59</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011</td>
      <td>1</td>
      <td>5</td>
      <td>3.80</td>
      <td>0.03</td>
      <td>0</td>
      <td>42</td>
      <td>38</td>
      <td>46.0</td>
      <td>45</td>
      <td>39</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



### >> 3. 数据展示（查看趋势）

#### 老特征plot图


```python
plt.style.use('fivethirtyeight')
# 设置布局
fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize = (10,10))
fig.autofmt_xdate(rotation = 45)

# 标签趋势
ax1.plot(dates, features['actual'])
ax1.set_xlabel('Date'); ax1.set_ylabel('Temperature'); ax1.set_title('acutal')

# 前一天温度
ax2.plot(dates, features['temp_1'])
ax2.set_xlabel('Date'); ax2.set_ylabel('Temperature'); ax2.set_title('temp_1')

# 前两天温度
ax3.plot(dates, features['temp_2'])
ax3.set_xlabel('Date'); ax3.set_ylabel('Temperature'); ax3.set_title('temp_2')

# Friend Estimate
ax4.plot(dates, features['friend'])
ax4.set_xlabel('Date'); ax4.set_ylabel('Temperature'); ax4.set_title('average')

plt.tight_layout(pad=2)
```


![image](https://github.com/listudystar/listudystar.github.io/raw/master/_posts/20190728_5.png)


##### 在数据分析和特征提取过程中，我们的出发点都是尽可能多的选择有价值的特征，因为起始阶段得到的信息越多，之后建模可以利用的信息也是越多。比如，这份数据中，我们有完整日期数据，但是显示天气变幻定于季节有关，但在原始数据集中并没有体现出季节指标，我们可以自己创建一个季节变量当做新的特征，无论是对之后建模还是分析都没有帮助。

#### 新特征plot图


```python
plt.style.use('fivethirtyeight')
# 设置布局
fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize = (10,10))
fig.autofmt_xdate(rotation = 45)

# 标签趋势
ax1.plot(dates, features['average'])
ax1.set_xlabel('Date'); ax1.set_ylabel('Temperature'); ax1.set_title('acutal')

# 前一天温度
ax2.plot(dates, features['ws_1'])
ax2.set_xlabel('Date'); ax2.set_ylabel('Temperature'); ax2.set_title('temp_1')

# 前两天温度
ax3.plot(dates, features['prcp_1'])
ax3.set_xlabel('Date'); ax3.set_ylabel('Temperature'); ax3.set_title('temp_2')

# Friend Estimate
ax4.plot(dates, features['snwd_1'],'ro')
ax4.set_xlabel('Date'); ax4.set_ylabel('Temperature'); ax4.set_title('average')

plt.tight_layout(pad=2)
```


![image](https://github.com/listudystar/listudystar.github.io/raw/master/_posts/20190728_6.png)


### >> 4. 创建新特征

#### 利用月份创建季节特征


```python
# 利用月份创建季节

seasons = []

for month in features['month']:
    if month in [1, 2, 12]:
        seasons.append('winter')
    elif month in [3, 4, 5]:
        seasons.append('spring')
    elif month in [6, 7, 8]:
        seasons.append('summer')
    elif month in [9, 10, 11]:
        seasons.append('fall')
        
# 创建6个特征组成的reduced_features
reduced_features = features[['temp_1', 'prcp_1', 'average', 'actual']]
reduced_features['season'] = seasons
```

    d:\ProgramData\Anaconda3\lib\site-packages\ipykernel_launcher.py:17: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
    


```python
reduced_features.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>temp_1</th>
      <th>prcp_1</th>
      <th>average</th>
      <th>actual</th>
      <th>season</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>37</td>
      <td>0.00</td>
      <td>45.6</td>
      <td>40</td>
      <td>winter</td>
    </tr>
    <tr>
      <th>1</th>
      <td>40</td>
      <td>0.00</td>
      <td>45.7</td>
      <td>39</td>
      <td>winter</td>
    </tr>
    <tr>
      <th>2</th>
      <td>39</td>
      <td>0.00</td>
      <td>45.8</td>
      <td>42</td>
      <td>winter</td>
    </tr>
    <tr>
      <th>3</th>
      <td>42</td>
      <td>0.00</td>
      <td>45.9</td>
      <td>38</td>
      <td>winter</td>
    </tr>
    <tr>
      <th>4</th>
      <td>38</td>
      <td>0.03</td>
      <td>46.0</td>
      <td>45</td>
      <td>winter</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 使用seaborn画
import seaborn as sns
sns.set(style="ticks", color_codes=True);

# 创建颜色模板
palette = sns.xkcd_palette(['dark blue', 'dark green', 'gold', 'orange'])

# 使用pair plot作图
sns.pairplot(reduced_features, hue = 'season', diag_kind = 'kde', palette= palette, plot_kws=dict(alpha = 0.7),
                   diag_kws=dict(shade=True));
```

![image](https://github.com/listudystar/listudystar.github.io/raw/master/_posts/20190728_7.png)


#### 结论：x轴和y轴都是我们这4项指标，不同颜色的点表示不同的季节，在主对角线上x轴和y轴都是相同特征，表示其在不同季节的数值分布情况，其他位置用散点图来表示两个特征之间的关系，例如temp_1和actual就呈现出很强的相关性。

### >> 5. 数据切分（训练集和测试集）


```python
features.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>ws_1</th>
      <th>prcp_1</th>
      <th>snwd_1</th>
      <th>temp_2</th>
      <th>temp_1</th>
      <th>average</th>
      <th>actual</th>
      <th>friend</th>
      <th>weekday_Fri</th>
      <th>weekday_Mon</th>
      <th>weekday_Sat</th>
      <th>weekday_Sun</th>
      <th>weekday_Thurs</th>
      <th>weekday_Tues</th>
      <th>weekday_Wed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>4.92</td>
      <td>0.00</td>
      <td>0</td>
      <td>36</td>
      <td>37</td>
      <td>45.6</td>
      <td>40</td>
      <td>40</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011</td>
      <td>1</td>
      <td>2</td>
      <td>5.37</td>
      <td>0.00</td>
      <td>0</td>
      <td>37</td>
      <td>40</td>
      <td>45.7</td>
      <td>39</td>
      <td>50</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011</td>
      <td>1</td>
      <td>3</td>
      <td>6.26</td>
      <td>0.00</td>
      <td>0</td>
      <td>40</td>
      <td>39</td>
      <td>45.8</td>
      <td>42</td>
      <td>42</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011</td>
      <td>1</td>
      <td>4</td>
      <td>5.59</td>
      <td>0.00</td>
      <td>0</td>
      <td>39</td>
      <td>42</td>
      <td>45.9</td>
      <td>38</td>
      <td>59</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011</td>
      <td>1</td>
      <td>5</td>
      <td>3.80</td>
      <td>0.03</td>
      <td>0</td>
      <td>42</td>
      <td>38</td>
      <td>46.0</td>
      <td>45</td>
      <td>39</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
features['season']= seasons
```


```python
features.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>ws_1</th>
      <th>prcp_1</th>
      <th>snwd_1</th>
      <th>temp_2</th>
      <th>temp_1</th>
      <th>average</th>
      <th>actual</th>
      <th>friend</th>
      <th>weekday_Fri</th>
      <th>weekday_Mon</th>
      <th>weekday_Sat</th>
      <th>weekday_Sun</th>
      <th>weekday_Thurs</th>
      <th>weekday_Tues</th>
      <th>weekday_Wed</th>
      <th>season</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>4.92</td>
      <td>0.00</td>
      <td>0</td>
      <td>36</td>
      <td>37</td>
      <td>45.6</td>
      <td>40</td>
      <td>40</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>winter</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011</td>
      <td>1</td>
      <td>2</td>
      <td>5.37</td>
      <td>0.00</td>
      <td>0</td>
      <td>37</td>
      <td>40</td>
      <td>45.7</td>
      <td>39</td>
      <td>50</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>winter</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011</td>
      <td>1</td>
      <td>3</td>
      <td>6.26</td>
      <td>0.00</td>
      <td>0</td>
      <td>40</td>
      <td>39</td>
      <td>45.8</td>
      <td>42</td>
      <td>42</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>winter</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011</td>
      <td>1</td>
      <td>4</td>
      <td>5.59</td>
      <td>0.00</td>
      <td>0</td>
      <td>39</td>
      <td>42</td>
      <td>45.9</td>
      <td>38</td>
      <td>59</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>winter</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011</td>
      <td>1</td>
      <td>5</td>
      <td>3.80</td>
      <td>0.03</td>
      <td>0</td>
      <td>42</td>
      <td>38</td>
      <td>46.0</td>
      <td>45</td>
      <td>39</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>winter</td>
    </tr>
  </tbody>
</table>
</div>




```python
features.shape
```




    (2191, 19)




```python
features = features.sample(frac = 1, random_state = 0) #洗牌
```


```python
#X_data = np.array(features.iloc[:, features.columns != 'actual']) # 数据集特征值
#y_data = np.array(features.iloc[:, features.columns == 'actual']) # 数据集标签值
```


```python
#from sklearn.model_selection import train_test_split
#X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.25,random_state = 0)
```


```python
#print('训练特征shape:', X_train.shape)
#print('训练标签shape:', y_train.shape)
#print('测试特征shape:', X_test.shape)
#print('测试标签shape:', y_test.shape)
```

### >> 6. 构建模型（RF模型）【增大数据量】


```python
features_1 = features.drop(['ws_1','prcp_1','snwd_1','season'],axis = 1)
```


```python
features_1.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>temp_2</th>
      <th>temp_1</th>
      <th>average</th>
      <th>actual</th>
      <th>friend</th>
      <th>weekday_Fri</th>
      <th>weekday_Mon</th>
      <th>weekday_Sat</th>
      <th>weekday_Sun</th>
      <th>weekday_Thurs</th>
      <th>weekday_Tues</th>
      <th>weekday_Wed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>39</th>
      <td>2011</td>
      <td>2</td>
      <td>9</td>
      <td>48</td>
      <td>46</td>
      <td>49.4</td>
      <td>45</td>
      <td>66</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>880</th>
      <td>2013</td>
      <td>5</td>
      <td>31</td>
      <td>61</td>
      <td>62</td>
      <td>67.3</td>
      <td>67</td>
      <td>74</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>391</th>
      <td>2012</td>
      <td>1</td>
      <td>27</td>
      <td>48</td>
      <td>48</td>
      <td>48.4</td>
      <td>44</td>
      <td>48</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1064</th>
      <td>2013</td>
      <td>12</td>
      <td>1</td>
      <td>49</td>
      <td>52</td>
      <td>47.4</td>
      <td>56</td>
      <td>64</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>251</th>
      <td>2011</td>
      <td>9</td>
      <td>9</td>
      <td>83</td>
      <td>85</td>
      <td>72.6</td>
      <td>85</td>
      <td>67</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
X_data_1 = features_1.iloc[:, features_1.columns != 'actual'] # 数据集特征值
y_data_1 = features_1.iloc[:, features_1.columns == 'actual']['actual'] # 数据集标签值

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_data_1, y_data_1, test_size = 0.25,random_state = 0)
```


```python
print('训练特征shape:', X_train.shape)
print('训练标签shape:', y_train.shape)
print('测试特征shape:', X_test.shape)
print('测试标签shape:', y_test.shape)
```

    训练特征shape: (1643, 14)
    训练标签shape: (1643,)
    测试特征shape: (548, 14)
    测试标签shape: (548,)
    

### >> 7. 训练及测试（RF模型）【增大数据量】


```python
y_train.head()
```




    836     59
    2095    67
    861     71
    1205    63
    357     52
    Name: actual, dtype: int64




```python
rf_most_important = RandomForestRegressor(n_estimators= 1000, random_state=0) # 创建RF对象

rf_most_important.fit(X_train, y_train) # 训练

predictions = rf_most_important.predict( X_test) # 预测

# 评估指标
errors = abs(predictions - np.array(y_test))
print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')

mape = np.mean(100 * (errors / np.array(y_test)))
accuracy = 100 - mape

print('Accuracy:', round(accuracy, 2), '%.')
```

    Mean Absolute Error: 3.86 degrees.
    Accuracy: 93.63 %.
    

#### 结论：增加特征，无提升


```python
features_2 = list(features.drop(['actual','ws_1','prcp_1','snwd_1','season'],axis = 1).columns)
importances = pd.Series(rf_most_important.feature_importances_, index = features_2).sort_values(ascending = False)
importances
```




    temp_1           0.840210
    average          0.061099
    friend           0.022004
    temp_2           0.019761
    day              0.018456
    year             0.013347
    month            0.006954
    weekday_Fri      0.003427
    weekday_Tues     0.002870
    weekday_Sun      0.002548
    weekday_Mon      0.002501
    weekday_Sat      0.002484
    weekday_Thurs    0.002400
    weekday_Wed      0.001940
    dtype: float64




```python
# 作图
x_values = list(range(len(importances))) # x_list
plt.bar(x_values, importances, orientation = 'vertical') # bar图
plt.xticks(x_values, importances.index, rotation='vertical') # 设置x显示值
plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances') # 轴显示值
```




    Text(0.5, 1.0, 'Variable Importances')




![image](https://github.com/listudystar/listudystar.github.io/raw/master/_posts/20190728_8.png)


### >> 8. 构建模型（RF模型）【加入新特征，采用完全数据】


```python
features.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>ws_1</th>
      <th>prcp_1</th>
      <th>snwd_1</th>
      <th>temp_2</th>
      <th>temp_1</th>
      <th>average</th>
      <th>actual</th>
      <th>friend</th>
      <th>weekday_Fri</th>
      <th>weekday_Mon</th>
      <th>weekday_Sat</th>
      <th>weekday_Sun</th>
      <th>weekday_Thurs</th>
      <th>weekday_Tues</th>
      <th>weekday_Wed</th>
      <th>season</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>39</th>
      <td>2011</td>
      <td>2</td>
      <td>9</td>
      <td>5.82</td>
      <td>0.00</td>
      <td>0</td>
      <td>48</td>
      <td>46</td>
      <td>49.4</td>
      <td>45</td>
      <td>66</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>winter</td>
    </tr>
    <tr>
      <th>880</th>
      <td>2013</td>
      <td>5</td>
      <td>31</td>
      <td>11.86</td>
      <td>0.00</td>
      <td>0</td>
      <td>61</td>
      <td>62</td>
      <td>67.3</td>
      <td>67</td>
      <td>74</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>spring</td>
    </tr>
    <tr>
      <th>391</th>
      <td>2012</td>
      <td>1</td>
      <td>27</td>
      <td>10.74</td>
      <td>0.19</td>
      <td>0</td>
      <td>48</td>
      <td>48</td>
      <td>48.4</td>
      <td>44</td>
      <td>48</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>winter</td>
    </tr>
    <tr>
      <th>1064</th>
      <td>2013</td>
      <td>12</td>
      <td>1</td>
      <td>8.72</td>
      <td>0.09</td>
      <td>0</td>
      <td>49</td>
      <td>52</td>
      <td>47.4</td>
      <td>56</td>
      <td>64</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>winter</td>
    </tr>
    <tr>
      <th>251</th>
      <td>2011</td>
      <td>9</td>
      <td>9</td>
      <td>2.91</td>
      <td>0.00</td>
      <td>0</td>
      <td>83</td>
      <td>85</td>
      <td>72.6</td>
      <td>85</td>
      <td>67</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>fall</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 因为存在 season 进行one hot编码
features = pd.get_dummies(features)
features.head(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>ws_1</th>
      <th>prcp_1</th>
      <th>snwd_1</th>
      <th>temp_2</th>
      <th>temp_1</th>
      <th>average</th>
      <th>actual</th>
      <th>...</th>
      <th>weekday_Mon</th>
      <th>weekday_Sat</th>
      <th>weekday_Sun</th>
      <th>weekday_Thurs</th>
      <th>weekday_Tues</th>
      <th>weekday_Wed</th>
      <th>season_fall</th>
      <th>season_spring</th>
      <th>season_summer</th>
      <th>season_winter</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>39</th>
      <td>2011</td>
      <td>2</td>
      <td>9</td>
      <td>5.82</td>
      <td>0.00</td>
      <td>0</td>
      <td>48</td>
      <td>46</td>
      <td>49.4</td>
      <td>45</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>880</th>
      <td>2013</td>
      <td>5</td>
      <td>31</td>
      <td>11.86</td>
      <td>0.00</td>
      <td>0</td>
      <td>61</td>
      <td>62</td>
      <td>67.3</td>
      <td>67</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>391</th>
      <td>2012</td>
      <td>1</td>
      <td>27</td>
      <td>10.74</td>
      <td>0.19</td>
      <td>0</td>
      <td>48</td>
      <td>48</td>
      <td>48.4</td>
      <td>44</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1064</th>
      <td>2013</td>
      <td>12</td>
      <td>1</td>
      <td>8.72</td>
      <td>0.09</td>
      <td>0</td>
      <td>49</td>
      <td>52</td>
      <td>47.4</td>
      <td>56</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>251</th>
      <td>2011</td>
      <td>9</td>
      <td>9</td>
      <td>2.91</td>
      <td>0.00</td>
      <td>0</td>
      <td>83</td>
      <td>85</td>
      <td>72.6</td>
      <td>85</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 22 columns</p>
</div>




```python
X_data_1 = features.iloc[:, features.columns != 'actual'] # 数据集特征值
y_data_1 = features.iloc[:, features.columns == 'actual']['actual'] # 数据集标签值

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_data_1, y_data_1, test_size = 0.25,random_state = 0)
```

### >> 9. 训练及测试（RF模型）【加入新特征，采用完全数据】


```python
rf_most_important = RandomForestRegressor(n_estimators= 1000, random_state=0) # 创建RF对象

rf_most_important.fit(X_train, y_train) # 训练

predictions = rf_most_important.predict( X_test) # 预测

# 评估指标
errors = abs(predictions - np.array(y_test))
print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')

mape = np.mean(100 * (errors / np.array(y_test)))
accuracy = 100 - mape

print('Accuracy:', round(accuracy, 2), '%.')
```

    Mean Absolute Error: 3.75 degrees.
    Accuracy: 93.78 %.
    

### >> 8. 特征重要性累加，选取95%之前的特征作为RF构建的特征


```python
features_2 = list(features,axis = 1).columns)
importances = pd.Series(rf_most_important.feature_importances_, index = features_2).sort_values(ascending = False)
importances
```


      File "<ipython-input-190-039e814eca59>", line 1
        features_2 = list(features,axis = 1).columns)
                                                    ^
    SyntaxError: invalid syntax
    



```python
# 画图重要性累加与95%横线
cumulative_importances = np.cumsum(importances) # 累计重要性 cumsum【（1，2，3，4）-> （1，3，6，10）】

plt.plot(x_values, cumulative_importances, 'g-')

plt.hlines(y = 0.95, xmin=0, xmax=len(importances.index), color = 'r', linestyles = 'dashed')

plt.xticks(x_values, importances.index, rotation = 'vertical')

plt.xlabel('Variable'); plt.ylabel('Cumulative Importance'); plt.title('Cumulative Importances');
```


![image](https://github.com/listudystar/listudystar.github.io/raw/master/_posts/20190728_9.png)



```python
print('特征重要性累加>=95%的数量:', np.where(cumulative_importances > 0.95)[0][0] + 1)
```

    特征重要性累加>=95%的数量: 5
    


```python
print('特征重要性累加>=95%的特征:', list(importances.index[:5]))
```

    特征重要性累加>=95%的特征: ['temp_1', 'average', 'friend', 'temp_2', 'day']
    

#### 结论：特征工程，选择特征比选模型，难度更大；
#### 特征降维：特征不要贪多！有些并不会使我们的效果变好

### >> 9. 用筛选出的95%之前的特征作为RF构建的特征


```python
important_indices = importances.index[:5] # 前5个是特征重要性累加>=95%的特征

# Create training and testing sets with only the important features
important_train_features = X_train[important_indices]
important_test_features = X_test[important_indices]

# Sanity check on operations
print('Important train features shape:', important_train_features.shape)
print('Important test features shape:', important_test_features.shape)
```

    Important train features shape: (1643, 5)
    Important test features shape: (548, 5)
    

### >> 10. 训练及测试（RF模型）


```python
rf_most_important = RandomForestRegressor(n_estimators= 1000, random_state=0) # 创建RF对象

rf_most_important.fit(important_train_features, y_train) # 训练

predictions = rf_most_important.predict(important_test_features) # 预测

# 评估指标
errors = abs(predictions - np.array(y_test))
print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')

mape = np.mean(100 * (errors / np.array(y_test)))
accuracy = 100 - mape

print('Accuracy:', round(accuracy, 2), '%.')
```

    Mean Absolute Error: 3.95 degrees.
    Accuracy: 93.51 %.
    

#### 结论：性能少许下降，其实随机森林的算法本身就会考虑特征问题，会优先选择有价值的，我们认为的去掉一些，相当于可供选择的就少了，出现这样的现象在随机森林中并不奇怪。

### >> 11. 时间效率评价（RF模型）


```python
import time

all_features_time = []

for _ in range(10): # 训练预测循环10次看，平均时间
    start_time = time.time()
    
    rf_most_important.fit(important_train_features, y_train) # 训练
    predictions = rf_most_important.predict(important_test_features) # 预测
    
    end_time = time.time()
    all_features_time.append(end_time - start_time)

all_features_time = np.mean(all_features_time)
print('采用所有特征用时:', round(all_features_time, 2), 'seconds.')
```

    采用所有特征用时: 4.61 seconds.
    

#### 结论：综合评价时候，应该考虑模型的训练时间和精度

## 3. 对RF进行调参，找到最合适参数

### >> 1. 默认 已经完成（数据载入，预处理，特征选择，数据切分）


```python
# important_train_features, y_train, important_test_features,y_test 这四类数据已经预备好

print('important_train_features.shape:' ,important_train_features.shape)
print('y_train.shape:', y_train.shape)
print('important_test_features.shape:', important_test_features.shape)
print('y_test.shape:', y_test.shape)
```

    important_train_features.shape: (1643, 5)
    y_train.shape: (1643,)
    important_test_features.shape: (548, 5)
    y_test.shape: (548,)
    


```python
feature_list = list(important_train_features.columns)
```

### >> 1. 调试模型参数

#### >> A. 默认参数


```python
from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(random_state = 0)

from pprint import pprint # pprint可以按行打印每个特征

# 查看RF参数
print('Parameters currently in use:\n')
pprint(rf.get_params()) 
```

    Parameters currently in use:
    
    {'bootstrap': True,
     'criterion': 'mse',
     'max_depth': None,
     'max_features': 'auto',
     'max_leaf_nodes': None,
     'min_impurity_decrease': 0.0,
     'min_impurity_split': None,
     'min_samples_leaf': 1,
     'min_samples_split': 2,
     'min_weight_fraction_leaf': 0.0,
     'n_estimators': 'warn',
     'n_jobs': None,
     'oob_score': False,
     'random_state': 0,
     'verbose': 0,
     'warm_start': False}
    

#### >> B. 参数大幅度调整（尝试各类参数）RandomizeSearchCV()

#### RandomizeSearchCV()，可以帮助我们在候选参数组合中，不断随机选择一组合适的参数来建模，并且求其交叉验证的评估结果。随机的目的是提高泛化能力和速度；


```python
from sklearn.model_selection import RandomizedSearchCV
```

##### 所要调整的参数


```python
# 随机森林树的数量
n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]
# 最大特征方式
max_features = ['auto', 'sqrt']
# 树的最大层数
max_depth = [int(x) for x in np.linspace(10, 100, num = 10)]
max_depth.append(None)
# 节点最小分裂所需样本个数
min_samples_split = [2, 5, 10]
# 叶子节点最小样本数，任何分裂不能让子节点样本数小于此值
min_samples_leaf = [1, 2, 4]
# 样本采样方法
bootstrap = [True, False]
```

##### 将以上参数设计为字典模式（构造参数空间）


```python
random_grid = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf,
               'bootstrap': bootstrap}
```


```python
rf = RandomForestRegressor() # 随机森林对象

rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,
                              n_iter = 100, scoring='neg_mean_absolute_error', 
                              cv = 3, verbose=2, random_state = 0, n_jobs=-1)
# estimator=rf表示错采样的算法，param_distributions=random_grid表示设计好的参数空间
# n_iter = 100表示迭代次数，scoring='neg_mean_absolute_error'表示评估方法
# cv = 3表示交叉验证分为3块数据，verbose=2表示输出信息，
# random_state = 0表示随机种子， n_jobs=-1表示所用的CPU情况
rf_random.fit(important_train_features, y_train)
```

    Fitting 3 folds for each of 100 candidates, totalling 300 fits
    

    [Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.
    [Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   35.4s
    [Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.7min
    [Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  5.4min finished
    




    RandomizedSearchCV(cv=3, error_score='raise-deprecating',
                       estimator=RandomForestRegressor(bootstrap=True,
                                                       criterion='mse',
                                                       max_depth=None,
                                                       max_features='auto',
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_impurity_split=None,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators='warn',
                                                       n_jobs=None, oob_score=False,
                                                       random_sta...
                       param_distributions={'bootstrap': [True, False],
                                            'max_depth': [10, 20, 30, 40, 50, 60,
                                                          70, 80, 90, 100, None],
                                            'max_features': ['auto', 'sqrt'],
                                            'min_samples_leaf': [1, 2, 4],
                                            'min_samples_split': [2, 5, 10],
                                            'n_estimators': [200, 400, 600, 800,
                                                             1000, 1200, 1400, 1600,
                                                             1800, 2000]},
                       pre_dispatch='2*n_jobs', random_state=0, refit=True,
                       return_train_score=False, scoring='neg_mean_absolute_error',
                       verbose=2)



##### 解除一组优参数组合


```python
rf_random.best_params_ #
```




    {'n_estimators': 800,
     'min_samples_split': 10,
     'min_samples_leaf': 4,
     'max_features': 'sqrt',
     'max_depth': 100,
     'bootstrap': True}



##### 评估（已经训练出采用最优参数的 rf_random 模型）


```python
predictions = rf_random.predict(important_test_features) # 预测

# 评估指标
errors = abs(predictions - np.array(y_test))
print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')

mape = np.mean(100 * (errors / np.array(y_test)))
accuracy = 100 - mape

print('Accuracy:', round(accuracy, 2), '%.')
```

    Mean Absolute Error: 3.84 degrees.
    Accuracy: 93.7 %.
    

#### >> B. 参数微调 Grid Search ()


```python
from sklearn.model_selection import GridSearchCV
```


```python
# 创建字典，进行网格搜索，交叉验证（【注意】创建在best_params_周围展开）
param_grid = {
    'bootstrap': [True],
    'max_depth': [80, 90, 100, 110],
    'max_features': [2, 3],
    'min_samples_leaf': [3, 4, 5],
    'min_samples_split': [8, 10, 12],
    'n_estimators': [100, 200, 300, 1000]
}
```


```python

rf = RandomForestRegressor()

# 初始化grid search模型（参数说明参考上文RandomizedSearchCV）
grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, 
                           scoring = 'neg_mean_absolute_error', cv = 3, 
                           n_jobs = -1, verbose = 2)
```


```python
grid_search.fit(important_train_features, y_train)
```

    Fitting 3 folds for each of 288 candidates, totalling 864 fits
    

    [Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.
    [Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    7.5s
    [Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   38.3s
    [Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.5min
    [Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  2.8min
    [Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed:  3.8min finished
    




    GridSearchCV(cv=3, error_score='raise-deprecating',
                 estimator=RandomForestRegressor(bootstrap=True, criterion='mse',
                                                 max_depth=None,
                                                 max_features='auto',
                                                 max_leaf_nodes=None,
                                                 min_impurity_decrease=0.0,
                                                 min_impurity_split=None,
                                                 min_samples_leaf=1,
                                                 min_samples_split=2,
                                                 min_weight_fraction_leaf=0.0,
                                                 n_estimators='warn', n_jobs=None,
                                                 oob_score=False, random_state=None,
                                                 verbose=0, warm_start=False),
                 iid='warn', n_jobs=-1,
                 param_grid={'bootstrap': [True], 'max_depth': [80, 90, 100, 110],
                             'max_features': [2, 3], 'min_samples_leaf': [3, 4, 5],
                             'min_samples_split': [8, 10, 12],
                             'n_estimators': [100, 200, 300, 1000]},
                 pre_dispatch='2*n_jobs', refit=True, return_train_score=False,
                 scoring='neg_mean_absolute_error', verbose=2)




```python
grid_search.best_params_
```




    {'bootstrap': True,
     'max_depth': 100,
     'max_features': 2,
     'min_samples_leaf': 5,
     'min_samples_split': 10,
     'n_estimators': 300}




```python
predictions = grid_search.predict(important_test_features) # 预测

# 评估指标
errors = abs(predictions - np.array(y_test))
print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')

mape = np.mean(100 * (errors / np.array(y_test)))
accuracy = 100 - mape

print('Accuracy:', round(accuracy, 2), '%.')
```

    Mean Absolute Error: 3.84 degrees.
    Accuracy: 93.7 %.
    
